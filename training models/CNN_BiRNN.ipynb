{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW6i741AFMGT",
        "outputId": "8a0f3356-783a-4099-fa0b-6f27b7ede659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import data\n",
        "import preprocess_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Bidirectional, GRU, concatenate, Conv1D\n",
        "from keras import layers\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = preprocess_data.Preprocess(data.Data())\n",
        "vrm = preprocess_data.VectorRepresentationModels(preprocess)\n",
        "w2v_model, w2v_Dict = vrm.word2vec(min_word_count=1)\n",
        "y = preprocess.y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbkibnvqFiBA",
        "outputId": "34633f28-9ee9-47ea-b045-65b691575d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:EPOCH - 1 : supplied example count (0) did not equal expected count (92735)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 1 : supplied raw word count (0) did not equal expected count (854176)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 2 : supplied example count (0) did not equal expected count (92735)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 2 : supplied raw word count (0) did not equal expected count (854176)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 3 : supplied example count (0) did not equal expected count (92735)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 3 : supplied raw word count (0) did not equal expected count (854176)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 4 : supplied example count (0) did not equal expected count (92735)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 4 : supplied raw word count (0) did not equal expected count (854176)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 5 : supplied example count (0) did not equal expected count (92735)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 5 : supplied raw word count (0) did not equal expected count (854176)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('clean_sents.pkl', 'rb') as file:\n",
        "  clean_sents = pickle.load(file)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "XZhN6d9RFneJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = []\n",
        "for sent in clean_sents:\n",
        "  s = [w2v_model.wv.vocab[w].index for w in sent]\n",
        "  S.append(s)"
      ],
      "metadata": {
        "id": "g1mEhYjlFqDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = tf.keras.utils.pad_sequences(S, padding=\"post\")\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(S, y, test_size=0.25, random_state=41, stratify=y)\n",
        "X_train_w2v, X_val_w2v, y_train_w2v, y_val_w2v = train_test_split(X_train_w2v, y_train_w2v, test_size=0.2)"
      ],
      "metadata": {
        "id": "BPq7xgffFrJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_mat = w2v_model.wv.vectors"
      ],
      "metadata": {
        "id": "w7BWN52OF6P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"gru_model.hdf5\"\n",
        "\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_mae\", verbose = 1,\n",
        "                              save_best_only = True, mode = \"min\")\n",
        "early_stop = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 5)\n",
        "\n",
        "inp = Input(shape = (524,),)\n",
        "embd = Embedding(embed_mat.shape[0], 300, weights = [embed_mat], trainable = False, mask_zero=True)(inp)\n",
        "conv = Conv1D(filters=32, kernel_size=4, activation='relu')(embd)\n",
        "pool1 = layers.AveragePooling1D(pool_size=2,name='pool_1')(conv)\n",
        "bi_gr1 = Bidirectional(GRU(64, dropout=0.4, recurrent_dropout=0.4, return_sequences=True))(pool1)\n",
        "bi_gr2 = Bidirectional(GRU(32, recurrent_dropout=0.4))(bi_gr1)\n",
        "drp = Dropout(0.5)(bi_gr2)\n",
        "out = Dense(1, activation='relu')(drp)\n",
        "model = Model(inputs=inp, outputs=out)\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVpZYc5Kdhfq",
        "outputId": "236edd8f-702e-47b2-a2c8-66042c5db850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 524)]             0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 524, 300)          7134000   \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 521, 32)           38432     \n",
            "                                                                 \n",
            " pool_1 (AveragePooling1D)   (None, 260, 32)           0         \n",
            "                                                                 \n",
            " bidirectional_12 (Bidirecti  (None, 260, 128)         37632     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 64)               31104     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,241,233\n",
            "Trainable params: 107,233\n",
            "Non-trainable params: 7,134,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_lstm = \"lstm_model.hdf5\"\n",
        "\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_mae\", verbose = 1,\n",
        "                              save_best_only = True, mode = \"min\")\n",
        "early_stop = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 5)\n",
        "\n",
        "inp = Input(shape = (524,),)\n",
        "embd = Embedding(embed_mat.shape[0], 300, weights = [embed_mat], trainable = False, mask_zero=True)(inp)\n",
        "conv = Conv1D(filters=32, kernel_size=4, activation='relu')(embd)\n",
        "pool1 = layers.AveragePooling1D(pool_size=2,name='pool_1')(conv)\n",
        "bi_gr1 = Bidirectional(LSTM(64, dropout=0.4, recurrent_dropout=0.4, return_sequences=True))(pool1)\n",
        "bi_gr2 = Bidirectional(LSTM(32, recurrent_dropout=0.4))(bi_gr1)\n",
        "drp = Dropout(0.5)(bi_gr2)\n",
        "out = Dense(1, activation='relu')(drp)\n",
        "model_lstm = Model(inputs=inp, outputs=out)\n",
        "model_lstm.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "model_lstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYNEBMSaGTAD",
        "outputId": "d5a33b22-ad82-494a-de38-6221f565f0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 524)]             0         \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, 524, 300)          7134000   \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 521, 32)           38432     \n",
            "                                                                 \n",
            " pool_1 (AveragePooling1D)   (None, 260, 32)           0         \n",
            "                                                                 \n",
            " bidirectional_18 (Bidirecti  (None, 260, 128)         49664     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_19 (Bidirecti  (None, 64)               41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,263,377\n",
            "Trainable params: 129,377\n",
            "Non-trainable params: 7,134,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.fit(X_train_w2v, y_train_w2v, batch_size=64, epochs=40, validation_data=(X_val_w2v, y_val_w2v), callbacks = [check_point, early_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HljAB5p_Gbp8",
        "outputId": "4d33414a-87a4-417d-fa9f-9610291445e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.9206 - mae: 0.7377\n",
            "Epoch 1: val_mae improved from inf to 0.61031, saving model to lstm_model.hdf5\n",
            "101/101 [==============================] - 165s 2s/step - loss: 0.9206 - mae: 0.7377 - val_loss: 0.5953 - val_mae: 0.6103\n",
            "Epoch 2/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6936 - mae: 0.6507\n",
            "Epoch 2: val_mae improved from 0.61031 to 0.56280, saving model to lstm_model.hdf5\n",
            "101/101 [==============================] - 156s 2s/step - loss: 0.6936 - mae: 0.6507 - val_loss: 0.5639 - val_mae: 0.5628\n",
            "Epoch 3/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6677 - mae: 0.6407\n",
            "Epoch 3: val_mae improved from 0.56280 to 0.54671, saving model to lstm_model.hdf5\n",
            "101/101 [==============================] - 154s 2s/step - loss: 0.6677 - mae: 0.6407 - val_loss: 0.5268 - val_mae: 0.5467\n",
            "Epoch 4/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6495 - mae: 0.6292\n",
            "Epoch 4: val_mae improved from 0.54671 to 0.53312, saving model to lstm_model.hdf5\n",
            "101/101 [==============================] - 156s 2s/step - loss: 0.6495 - mae: 0.6292 - val_loss: 0.5141 - val_mae: 0.5331\n",
            "Epoch 5/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6211 - mae: 0.6139\n",
            "Epoch 5: val_mae did not improve from 0.53312\n",
            "101/101 [==============================] - 155s 2s/step - loss: 0.6211 - mae: 0.6139 - val_loss: 0.5884 - val_mae: 0.5746\n",
            "Epoch 6/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6090 - mae: 0.6101\n",
            "Epoch 6: val_mae did not improve from 0.53312\n",
            "101/101 [==============================] - 154s 2s/step - loss: 0.6090 - mae: 0.6101 - val_loss: 0.5111 - val_mae: 0.5492\n",
            "Epoch 7/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5814 - mae: 0.5941\n",
            "Epoch 7: val_mae improved from 0.53312 to 0.52806, saving model to lstm_model.hdf5\n",
            "101/101 [==============================] - 155s 2s/step - loss: 0.5814 - mae: 0.5941 - val_loss: 0.4926 - val_mae: 0.5281\n",
            "Epoch 8/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5691 - mae: 0.5848\n",
            "Epoch 8: val_mae did not improve from 0.52806\n",
            "101/101 [==============================] - 153s 2s/step - loss: 0.5691 - mae: 0.5848 - val_loss: 0.5127 - val_mae: 0.5314\n",
            "Epoch 9/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5566 - mae: 0.5843\n",
            "Epoch 9: val_mae did not improve from 0.52806\n",
            "101/101 [==============================] - 155s 2s/step - loss: 0.5566 - mae: 0.5843 - val_loss: 0.5042 - val_mae: 0.5404\n",
            "Epoch 10/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5413 - mae: 0.5742\n",
            "Epoch 10: val_mae did not improve from 0.52806\n",
            "101/101 [==============================] - 155s 2s/step - loss: 0.5413 - mae: 0.5742 - val_loss: 0.5109 - val_mae: 0.5447\n",
            "Epoch 11/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5229 - mae: 0.5636\n",
            "Epoch 11: val_mae did not improve from 0.52806\n",
            "101/101 [==============================] - 153s 2s/step - loss: 0.5229 - mae: 0.5636 - val_loss: 0.5071 - val_mae: 0.5366\n",
            "Epoch 12/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5034 - mae: 0.5545\n",
            "Epoch 12: val_mae did not improve from 0.52806\n",
            "101/101 [==============================] - 155s 2s/step - loss: 0.5034 - mae: 0.5545 - val_loss: 0.5174 - val_mae: 0.5424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b4bbd30d0>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_w2v, y_train_w2v, batch_size=64, epochs=40, validation_data=(X_val_w2v, y_val_w2v), callbacks = [check_point, early_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRhOAqMXd1Of",
        "outputId": "e669381f-0f47-42b6-d1ef-4e71a9f5f559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 1.0815 - mae: 0.8152\n",
            "Epoch 1: val_mae improved from inf to 0.72224, saving model to our_test_model.hdf5\n",
            "101/101 [==============================] - 166s 2s/step - loss: 1.0815 - mae: 0.8152 - val_loss: 0.8004 - val_mae: 0.7222\n",
            "Epoch 2/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.7455 - mae: 0.6732\n",
            "Epoch 2: val_mae did not improve from 0.72224\n",
            "101/101 [==============================] - 145s 1s/step - loss: 0.7455 - mae: 0.6732 - val_loss: 0.8934 - val_mae: 0.7768\n",
            "Epoch 3/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6916 - mae: 0.6504\n",
            "Epoch 3: val_mae improved from 0.72224 to 0.54775, saving model to our_test_model.hdf5\n",
            "101/101 [==============================] - 140s 1s/step - loss: 0.6916 - mae: 0.6504 - val_loss: 0.5091 - val_mae: 0.5477\n",
            "Epoch 4/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6587 - mae: 0.6283\n",
            "Epoch 4: val_mae did not improve from 0.54775\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.6587 - mae: 0.6283 - val_loss: 0.5134 - val_mae: 0.5534\n",
            "Epoch 5/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6337 - mae: 0.6222\n",
            "Epoch 5: val_mae improved from 0.54775 to 0.54391, saving model to our_test_model.hdf5\n",
            "101/101 [==============================] - 142s 1s/step - loss: 0.6337 - mae: 0.6222 - val_loss: 0.5033 - val_mae: 0.5439\n",
            "Epoch 6/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.6130 - mae: 0.6112\n",
            "Epoch 6: val_mae did not improve from 0.54391\n",
            "101/101 [==============================] - 138s 1s/step - loss: 0.6130 - mae: 0.6112 - val_loss: 0.5451 - val_mae: 0.5744\n",
            "Epoch 7/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5771 - mae: 0.5928\n",
            "Epoch 7: val_mae did not improve from 0.54391\n",
            "101/101 [==============================] - 138s 1s/step - loss: 0.5771 - mae: 0.5928 - val_loss: 0.5281 - val_mae: 0.5565\n",
            "Epoch 8/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5756 - mae: 0.5935\n",
            "Epoch 8: val_mae did not improve from 0.54391\n",
            "101/101 [==============================] - 139s 1s/step - loss: 0.5756 - mae: 0.5935 - val_loss: 0.6019 - val_mae: 0.6148\n",
            "Epoch 9/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5642 - mae: 0.5903\n",
            "Epoch 9: val_mae did not improve from 0.54391\n",
            "101/101 [==============================] - 140s 1s/step - loss: 0.5642 - mae: 0.5903 - val_loss: 0.6313 - val_mae: 0.5985\n",
            "Epoch 10/40\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5464 - mae: 0.5756\n",
            "Epoch 10: val_mae did not improve from 0.54391\n",
            "101/101 [==============================] - 138s 1s/step - loss: 0.5464 - mae: 0.5756 - val_loss: 0.5072 - val_mae: 0.5452\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8be1051520>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n"
      ],
      "metadata": {
        "id": "jk8pOKYenD9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(file_path)"
      ],
      "metadata": {
        "id": "W-by42NtmW7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = load_model(file_path_lstm)\n",
        "p = model_lstm.predict(X_test_w2v)\n",
        "y_pred = np.around(p)\n",
        "result_aug = cohen_kappa_score(y_test_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB2BcqFUGfg9",
        "outputId": "5d903d75-cc74-4847-d3f7-72ac380f1bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 14s 161ms/step\n",
            "Kappa Score: 0.7076978468604643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model.predict(X_test_w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls6GEkqNmhlU",
        "outputId": "7efb6bb0-26bd-4f8b-a569-45051cc57403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 16s 178ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred = model.predict(x_test)\n",
        "import numpy as np\n",
        "y_pred = np.around(p)\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "result_aug = cohen_kappa_score(y_test_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g934rTVxnY70",
        "outputId": "6bca16cb-916a-4979-e4c9-1c32659ad57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kappa Score: 0.6801462912265145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####gen_new_data"
      ],
      "metadata": {
        "id": "USsFmKEExkq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_syn = {}\n",
        "for word in w2v_Dict.keys():\n",
        "  w2v_syn[word] = w2v_model.wv.most_similar(word)[0][0]\n",
        "\n",
        "w2v_ant = {}\n",
        "for word in w2v_Dict.keys():\n",
        "  w2v_ant[word] = w2v_model.wv.most_similar(negative=[word])[0][0]"
      ],
      "metadata": {
        "id": "USVNNnfDn36r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from generation import GEN_SAMPLES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxG2-PHaotDp",
        "outputId": "51076f67-50c6-4045-a0e5-86fc70054981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate new data using w2v model\n",
        "gen_samples_w2v = GEN_SAMPLES(vrm, w2v_model, w2v_Dict, w2v_syn, w2v_ant)\n",
        "new_samples_w2v, new_grad_w2v = gen_samples_w2v.generate_samples()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAeDRN63oUQn",
        "outputId": "6c928dba-3a6c-4dfb-9b89-0cddbb3b6505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vec = vrm.cleanSent_vec(w2v_model, w2v_Dict)"
      ],
      "metadata": {
        "id": "p2pDTWgcp-Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from generation import GEN_VECTORS"
      ],
      "metadata": {
        "id": "TNDa-a4CqS7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creation of new vectors using w2v model\n",
        "gen_vec_w2v = GEN_VECTORS(new_samples_w2v, new_grad_w2v, vrm, w2v_model, w2v_Dict)\n",
        "new_x_w2v = gen_vec_w2v.generate_vectors(y)\n",
        "new_y_w2v = gen_vec_w2v.generate_grades(new_x_w2v, w2v_vec, y)"
      ],
      "metadata": {
        "id": "uY1I3xjVo4Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_x_w2v), len(new_y_w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyQZiW8ku9jj",
        "outputId": "7f14dd9a-5b5f-4749-963d-35c40b927ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12372, 12372)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_samples_w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw1fJ4AewEMk",
        "outputId": "ba59399e-7810-4998-f8eb-ca3b2bf1e9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12372"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim import models\n",
        "\n",
        "word2vec_path = '/content/word2VecModel.bin'\n",
        "w2v_model = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
      ],
      "metadata": {
        "id": "H9F0cB2dsqHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_vocab = w2v_model.wv.vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csdklzWctdyX",
        "outputId": "100a11f2-ab3d-4070-9c2f-9dd3d7312e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-134-1b02b1a00d82>:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  w2v_vocab = w2v_model.wv.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_S = []\n",
        "for sent in new_samples_w2v:\n",
        "  s = [w2v_vocab[w].index for w in sent if w in w2v_vocab]\n",
        "  new_S.append(s)"
      ],
      "metadata": {
        "id": "eNGL0ZBSqYDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_S), len(new_y_w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1GNgWuiwVUT",
        "outputId": "9dd8d9ca-daea-4aec-a9a2-f77960ef1aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12372, 12372)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_S = tf.keras.utils.pad_sequences(new_S, padding=\"post\", maxlen=524)\n"
      ],
      "metadata": {
        "id": "tDPu4kLXwuRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X_train_w2v, new_X_test_w2v, new_y_train_w2v, new_y_test_w2v = train_test_split(new_S, new_y_w2v, test_size=0.25, random_state=41)\n",
        "# new_X_train_w2v, new_X_val_w2v, new_y_train_w2v, new_y_val_w2v = train_test_split(X_train_w2v, y_train_w2v, test_size=0.2)"
      ],
      "metadata": {
        "id": "YPdfVEgitwQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_lstm.predict(new_X_train_w2v)\n",
        "y_pred = np.around(y_pred)\n",
        "result_aug = cohen_kappa_score(new_y_train_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y6WWIuugUNV",
        "outputId": "6a53ac9a-b055-4bb1-a0d7-67f7d2e452ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "290/290 [==============================] - 47s 161ms/step\n",
            "Kappa Score: 0.5251998847408686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(new_X_train_w2v)\n",
        "y_pred = np.around(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkj0inPbudL4",
        "outputId": "217c06c4-ea2f-4433-9d05-96a58fb4ba79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "290/290 [==============================] - 44s 150ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_aug = cohen_kappa_score(new_y_train_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKC5LI6QxSVP",
        "outputId": "f2867773-b5b6-4454-bbdb-b9ffc14da2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kappa Score: 0.5144093914665215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####aug_data"
      ],
      "metadata": {
        "id": "Z8QkZpYN2JSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from generation import AUGSAM"
      ],
      "metadata": {
        "id": "Ta-oNoQr03mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_vec_w2v, aug_y_w2v = AUGSAM(S, y, new_S, new_y_w2v)()"
      ],
      "metadata": {
        "id": "9zDjOREa0-24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X_train_w2v, new_X_test_w2v, new_y_train_w2v, new_y_test_w2v = train_test_split(aug_vec_w2v, aug_y_w2v, test_size=0.25)\n",
        "new_X_train_w2v, new_X_val_w2v, new_y_train_w2v, new_y_val_w2v = train_test_split(X_train_w2v, y_train_w2v, test_size=0.2)"
      ],
      "metadata": {
        "id": "DJKHdzd501BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.fit(new_X_train_w2v, new_y_train_w2v, batch_size=64, epochs=40, validation_data=(new_X_val_w2v, new_y_val_w2v), callbacks = [check_point, early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQKtKYbKgxRY",
        "outputId": "ed9c0a98-2495-4cd0-b960-f42c82ddbc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.9606 - mae: 0.7507\n",
            "Epoch 1: val_mae improved from inf to 0.57961, saving model to lstm_model.hdf5\n",
            "81/81 [==============================] - 154s 2s/step - loss: 0.9606 - mae: 0.7507 - val_loss: 0.5665 - val_mae: 0.5796\n",
            "Epoch 2/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.7100 - mae: 0.6568\n",
            "Epoch 2: val_mae did not improve from 0.57961\n",
            "81/81 [==============================] - 126s 2s/step - loss: 0.7100 - mae: 0.6568 - val_loss: 0.6004 - val_mae: 0.5798\n",
            "Epoch 3/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6774 - mae: 0.6401\n",
            "Epoch 3: val_mae improved from 0.57961 to 0.57567, saving model to lstm_model.hdf5\n",
            "81/81 [==============================] - 128s 2s/step - loss: 0.6774 - mae: 0.6401 - val_loss: 0.5402 - val_mae: 0.5757\n",
            "Epoch 4/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6533 - mae: 0.6366\n",
            "Epoch 4: val_mae improved from 0.57567 to 0.57357, saving model to lstm_model.hdf5\n",
            "81/81 [==============================] - 124s 2s/step - loss: 0.6533 - mae: 0.6366 - val_loss: 0.5323 - val_mae: 0.5736\n",
            "Epoch 5/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6325 - mae: 0.6219\n",
            "Epoch 5: val_mae improved from 0.57357 to 0.56040, saving model to lstm_model.hdf5\n",
            "81/81 [==============================] - 127s 2s/step - loss: 0.6325 - mae: 0.6219 - val_loss: 0.5220 - val_mae: 0.5604\n",
            "Epoch 6/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6081 - mae: 0.6060\n",
            "Epoch 6: val_mae improved from 0.56040 to 0.56001, saving model to lstm_model.hdf5\n",
            "81/81 [==============================] - 124s 2s/step - loss: 0.6081 - mae: 0.6060 - val_loss: 0.5693 - val_mae: 0.5600\n",
            "Epoch 7/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5898 - mae: 0.5987\n",
            "Epoch 7: val_mae improved from 0.56001 to 0.54451, saving model to lstm_model.hdf5\n",
            "81/81 [==============================] - 127s 2s/step - loss: 0.5898 - mae: 0.5987 - val_loss: 0.5120 - val_mae: 0.5445\n",
            "Epoch 8/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5743 - mae: 0.5938\n",
            "Epoch 8: val_mae did not improve from 0.54451\n",
            "81/81 [==============================] - 124s 2s/step - loss: 0.5743 - mae: 0.5938 - val_loss: 0.6716 - val_mae: 0.6574\n",
            "Epoch 9/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5537 - mae: 0.5816\n",
            "Epoch 9: val_mae did not improve from 0.54451\n",
            "81/81 [==============================] - 127s 2s/step - loss: 0.5537 - mae: 0.5816 - val_loss: 0.5844 - val_mae: 0.5807\n",
            "Epoch 10/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5362 - mae: 0.5704\n",
            "Epoch 10: val_mae did not improve from 0.54451\n",
            "81/81 [==============================] - 124s 2s/step - loss: 0.5362 - mae: 0.5704 - val_loss: 0.5439 - val_mae: 0.5503\n",
            "Epoch 11/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5225 - mae: 0.5636\n",
            "Epoch 11: val_mae did not improve from 0.54451\n",
            "81/81 [==============================] - 127s 2s/step - loss: 0.5225 - mae: 0.5636 - val_loss: 0.5485 - val_mae: 0.5627\n",
            "Epoch 12/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.4903 - mae: 0.5456\n",
            "Epoch 12: val_mae did not improve from 0.54451\n",
            "81/81 [==============================] - 124s 2s/step - loss: 0.4903 - mae: 0.5456 - val_loss: 0.5940 - val_mae: 0.5855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b564f6520>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(new_X_train_w2v, new_y_train_w2v, batch_size=64, epochs=40, validation_data=(new_X_val_w2v, new_y_val_w2v), callbacks = [check_point, early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbjAwTOD1ZQv",
        "outputId": "fde7557e-14c7-4c7d-e154-2073227eb7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1523 - mae: 0.8318\n",
            "Epoch 1: val_mae improved from inf to 0.60680, saving model to our_test_model.hdf5\n",
            "81/81 [==============================] - 120s 1s/step - loss: 1.1523 - mae: 0.8318 - val_loss: 0.5996 - val_mae: 0.6068\n",
            "Epoch 2/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.7562 - mae: 0.6795\n",
            "Epoch 2: val_mae improved from 0.60680 to 0.58671, saving model to our_test_model.hdf5\n",
            "81/81 [==============================] - 110s 1s/step - loss: 0.7562 - mae: 0.6795 - val_loss: 0.5967 - val_mae: 0.5867\n",
            "Epoch 3/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.7068 - mae: 0.6534\n",
            "Epoch 3: val_mae did not improve from 0.58671\n",
            "81/81 [==============================] - 115s 1s/step - loss: 0.7068 - mae: 0.6534 - val_loss: 0.6194 - val_mae: 0.5933\n",
            "Epoch 4/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6788 - mae: 0.6473\n",
            "Epoch 4: val_mae improved from 0.58671 to 0.57634, saving model to our_test_model.hdf5\n",
            "81/81 [==============================] - 110s 1s/step - loss: 0.6788 - mae: 0.6473 - val_loss: 0.5532 - val_mae: 0.5763\n",
            "Epoch 5/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6581 - mae: 0.6351\n",
            "Epoch 5: val_mae did not improve from 0.57634\n",
            "81/81 [==============================] - 112s 1s/step - loss: 0.6581 - mae: 0.6351 - val_loss: 0.6205 - val_mae: 0.5907\n",
            "Epoch 6/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6234 - mae: 0.6156\n",
            "Epoch 6: val_mae improved from 0.57634 to 0.56375, saving model to our_test_model.hdf5\n",
            "81/81 [==============================] - 110s 1s/step - loss: 0.6234 - mae: 0.6156 - val_loss: 0.5410 - val_mae: 0.5637\n",
            "Epoch 7/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.6099 - mae: 0.6070\n",
            "Epoch 7: val_mae did not improve from 0.56375\n",
            "81/81 [==============================] - 112s 1s/step - loss: 0.6099 - mae: 0.6070 - val_loss: 0.5514 - val_mae: 0.5719\n",
            "Epoch 8/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5839 - mae: 0.5966\n",
            "Epoch 8: val_mae improved from 0.56375 to 0.55548, saving model to our_test_model.hdf5\n",
            "81/81 [==============================] - 110s 1s/step - loss: 0.5839 - mae: 0.5966 - val_loss: 0.5322 - val_mae: 0.5555\n",
            "Epoch 9/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5672 - mae: 0.5861\n",
            "Epoch 9: val_mae did not improve from 0.55548\n",
            "81/81 [==============================] - 110s 1s/step - loss: 0.5672 - mae: 0.5861 - val_loss: 0.6614 - val_mae: 0.6523\n",
            "Epoch 10/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5445 - mae: 0.5783\n",
            "Epoch 10: val_mae did not improve from 0.55548\n",
            "81/81 [==============================] - 112s 1s/step - loss: 0.5445 - mae: 0.5783 - val_loss: 0.6343 - val_mae: 0.6337\n",
            "Epoch 11/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5021 - mae: 0.5555\n",
            "Epoch 11: val_mae did not improve from 0.55548\n",
            "81/81 [==============================] - 110s 1s/step - loss: 0.5021 - mae: 0.5555 - val_loss: 0.6111 - val_mae: 0.6202\n",
            "Epoch 12/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.5101 - mae: 0.5588\n",
            "Epoch 12: val_mae did not improve from 0.55548\n",
            "81/81 [==============================] - 112s 1s/step - loss: 0.5101 - mae: 0.5588 - val_loss: 0.6008 - val_mae: 0.5989\n",
            "Epoch 13/40\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.4876 - mae: 0.5482\n",
            "Epoch 13: val_mae did not improve from 0.55548\n",
            "81/81 [==============================] - 110s 1s/step - loss: 0.4876 - mae: 0.5482 - val_loss: 0.6414 - val_mae: 0.6148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b50a07a60>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_aug = load_model(file_path)"
      ],
      "metadata": {
        "id": "_mrjUbnd5L3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm_aug = load_model(file_path_lstm)"
      ],
      "metadata": {
        "id": "VQMePOXHhKKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_lstm_aug.predict(new_X_test_w2v)\n",
        "y_pred = np.around(y_pred)\n",
        "result_aug = cohen_kappa_score(new_y_test_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))\n",
        "\n",
        "# y_pred = model.predict(x_test)\n",
        "p = model_lstm_aug.predict(X_test_w2v)\n",
        "y_pred = np.around(p)\n",
        "\n",
        "result_aug = cohen_kappa_score(y_test_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVZ3w2FbhMDW",
        "outputId": "ff39cef0-d9a5-422b-deb3-2952a3cc9b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181/181 [==============================] - 34s 184ms/step\n",
            "Kappa Score: 0.6413153000406977\n",
            "84/84 [==============================] - 15s 163ms/step\n",
            "Kappa Score: 0.7164432235340807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_aug.predict(new_X_test_w2v)\n",
        "y_pred = np.around(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE2zXkQC1q74",
        "outputId": "08ee36d9-1dc9-4a26-9048-87184f828b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181/181 [==============================] - 27s 143ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_aug = cohen_kappa_score(new_y_test_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcNnuHDN108S",
        "outputId": "eb5fa623-798c-412f-d739-57e3cb0180d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kappa Score: 0.6345474549280177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred = model.predict(x_test)\n",
        "p = model_aug.predict(X_test_w2v)\n",
        "y_pred = np.around(p)\n",
        "\n",
        "result_aug = cohen_kappa_score(y_test_w2v,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OxxA7h215c7",
        "outputId": "6ea920e9-51db-411b-a5b1-8147eb1e449b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - 13s 141ms/step\n",
            "Kappa Score: 0.7030067313045353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3F8IE_Wg-_vC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}